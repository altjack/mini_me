#!/usr/bin/env python3
"""
Script principale per eseguire l'agente on-demand.

Usage:
    uv run run_agent.py
    
Questo script:
1. Carica la configurazione da config.yaml
2. Crea l'agente con memoria Redis
3. Esegue il task configurato
4. Salva il draft per approvazione manuale

Workflow:
    run_agent.py -> email/draft_email.md -> approve_draft.py -> Redis memory
"""

import yaml
import os
import sys
import logging
from datetime import datetime
from pathlib import Path

# Aggiungi directory corrente al path
sys.path.append(os.path.dirname(__file__))

from agent.agent import create_agent_with_memory


def setup_logging(config: dict) -> logging.Logger:
    """
    Configura logging per l'esecuzione.
    
    Args:
        config: Dizionario configurazione
    
    Returns:
        Logger configurato
    """
    log_level = config.get('logging', {}).get('level', 'INFO')
    log_file = config.get('logging', {}).get('agent_log', 'agent_execution.log')
    
    # Configura formato
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__)


def load_config(config_path: str = "config.yaml") -> dict:
    """
    Carica configurazione da file YAML.
    
    Args:
        config_path: Percorso al file di configurazione
    
    Returns:
        Dizionario con configurazione
    """
    if not os.path.exists(config_path):
        raise FileNotFoundError(
            f"File di configurazione non trovato: {config_path}\n"
            "Assicurati che config.yaml sia presente nella directory."
        )
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return config


def ensure_directories(config: dict) -> None:
    """
    Crea le directory necessarie se non esistono.
    
    Args:
        config: Dizionario configurazione
    """
    output_dir = config['execution']['output_dir']
    archive_dir = config['execution']['archive_dir']
    
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    Path(archive_dir).mkdir(parents=True, exist_ok=True)


def check_data_availability(config: dict, logger: logging.Logger) -> bool:
    """
    Verifica che i dati GA4 siano disponibili nel database.
    
    Args:
        config: Dizionario configurazione
        logger: Logger per messaggi
    
    Returns:
        True se dati disponibili, False altrimenti
    """
    try:
        from ga4_extraction.database import GA4Database
        
        # Carica configurazione database
        db_config = config.get('database', {})
        db_path = db_config.get('sqlite', {}).get('path', 'data/ga4_data.db')
        
        # Verifica esistenza file database
        if not os.path.exists(db_path):
            logger.error(f"Database non trovato: {db_path}")
            logger.info("Esegui prima: uv run setup_database.py")
            return False
        
        # Verifica che ci siano dati nel database
        db = GA4Database(db_path)
        stats = db.get_statistics()
        db.close()
        
        if stats['record_count'] == 0:
            logger.error("Database vuoto - nessun dato disponibile")
            logger.info("Esegui prima: uv run backfill_ga4.py")
            return False
        
        logger.info(f"‚úì Database contiene {stats['record_count']} record")
        logger.info(f"   Periodo: {stats['min_date']} ‚Üí {stats['max_date']}")
        return True
        
    except Exception as e:
        logger.error(f"Errore verifica database: {e}")
        logger.info("Esegui prima: uv run setup_database.py")
        return False


def save_draft(content: str, config: dict, logger: logging.Logger) -> str:
    """
    Salva il draft dell'email generata.
    
    Args:
        content: Contenuto email generato
        config: Dizionario configurazione
        logger: Logger per messaggi
    
    Returns:
        Percorso al file draft salvato
    """
    output_dir = config['execution']['output_dir']
    draft_filename = config['execution']['draft_filename']
    draft_path = os.path.join(output_dir, draft_filename)
    
    # Crea header con metadata
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    header = f"""# Draft Email - {timestamp}

**Status:** In attesa di approvazione  
**Generated by:** Agent Daily Report  
**Data source:** {config['execution']['data_source']}

---

"""
    
    # Salva file
    with open(draft_path, 'w', encoding='utf-8') as f:
        f.write(header)
        f.write(content)
    
    logger.info(f"‚úì Draft salvato: {draft_path}")
    
    return draft_path


def run_agent_workflow(config: dict, logger: logging.Logger = None, skip_data_check: bool = False) -> str:
    """
    Esegue il workflow dell'agente per generare la draft email.
    
    Args:
        config: Dizionario configurazione
        logger: Logger opzionale (se None, viene creato automaticamente)
        skip_data_check: Se True, salta il check disponibilit√† dati (default: False)
    
    Returns:
        Percorso al file draft generato
        
    Raises:
        Exception: Se l'esecuzione fallisce
    """
    # Setup logging se non fornito
    if logger is None:
        logger = setup_logging(config)
    
    logger.info("=== Inizio esecuzione agent workflow ===")
    
    # 1. Verifica directory
    ensure_directories(config)
    logger.info("‚úì Directory configurate")
    
    # 2. Verifica disponibilit√† dati (se richiesto)
    if not skip_data_check:
        if not check_data_availability(config, logger):
            raise RuntimeError(
                "Dati GA4 non disponibili. "
                "Esegui prima l'estrazione dati o usa skip_data_check=True"
            )
        logger.info("‚úì Dati GA4 disponibili")
    
    # 3. Crea agente con memoria
    model = config['agent']['model']
    verbose = config['agent']['verbose']
    
    try:
        agent = create_agent_with_memory(model=model, verbose=verbose)
        logger.info(f"‚úì Agente creato (model: {model})")
    except Exception as e:
        logger.error(f"Errore creazione agente: {e}")
        
        if "Redis" in str(e) or "redis" in str(e):
            raise RuntimeError(
                f"Errore Redis: {e}\n"
                "Verifica:\n"
                "  1. Redis √® installato? -> brew install redis\n"
                "  2. Redis √® avviato? -> redis-server\n"
                "  3. Memoria caricata? -> python agent/load_memory.py"
            )
        raise
    
    # 4. Esegui task
    task_prompt = config['execution']['task_prompt']
    logger.info(f"Task prompt: {task_prompt[:100]}...")
    
    try:
        result = agent.run(task_prompt)
        logger.info("Task completato con successo")
    except Exception as e:
        logger.error(f"Errore esecuzione task: {e}", exc_info=True)
        raise RuntimeError(f"Errore durante esecuzione agente: {e}")
    
    # 5. Estrai contenuto dalla risposta
    def extract_content(obj):
        """Estrae ricorsivamente il contenuto da qualsiasi tipo di oggetto"""
        if isinstance(obj, str):
            return obj
        elif isinstance(obj, list):
            # Per liste, cerca elementi con content/text e skip tool calls
            parts = []
            for item in obj:
                # Skip FunctionCallBlock e FunctionCallResultBlock
                item_type = type(item).__name__
                if 'FunctionCall' in item_type or 'Block' in item_type:
                    continue
                
                extracted = extract_content(item)
                if extracted and extracted.strip():
                    parts.append(extracted)
            return "\n".join(parts) if parts else ""
        # Per StepResult, accedi direttamente all'attributo text
        elif hasattr(obj, 'text'):
            text_val = obj.text
            # Se text √® una stringa, ritornala
            if isinstance(text_val, str):
                return text_val
            # Altrimenti recursione
            return extract_content(text_val)
        # Prova altri attributi comuni
        elif hasattr(obj, 'content'):
            content = obj.content
            # Se content √® una lista, filtra tool blocks
            if isinstance(content, list):
                text_parts = []
                for item in content:
                    if hasattr(item, 'text'):
                        text_parts.append(item.text)
                    elif isinstance(item, str):
                        text_parts.append(item)
                return "\n".join(text_parts) if text_parts else extract_content(content)
            return extract_content(content)
        elif hasattr(obj, 'message'):
            return extract_content(obj.message)
        else:
            # Solo come ultimo resort
            obj_str = str(obj)
            # Se contiene "FunctionCall" o "Block", ritorna vuoto
            if 'FunctionCall' in obj_str or 'Block' in obj_str:
                return ""
            return obj_str
    
    # DEBUG: Esamina struttura StepResult
    logger.info(f"Tipo risultato: {type(result)}")
    logger.info(f"Attributi disponibili: {dir(result)}")
    if hasattr(result, '__dict__'):
        logger.info(f"__dict__: {result.__dict__.keys()}")
    
    result_str = extract_content(result)
    
    # Se il risultato √® vuoto o troppo corto, prova altri metodi
    if not result_str or len(result_str) < 100:
        logger.warning(f"Estrazione standard fallita, provo metodi alternativi")
        
        # Prova attributi diretti
        for attr in ['final_answer', 'answer', 'response', 'output', 'result']:
            if hasattr(result, attr):
                value = getattr(result, attr)
                logger.info(f"Trovato attributo {attr}: {type(value)}")
                result_str = extract_content(value)
                if result_str and len(result_str) > 100:
                    logger.info(f"‚úì Successo con attributo: {attr}")
                    break
    
    # Se ancora vuoto, fallimento
    if not result_str or len(result_str) < 100:
        logger.error(f"Contenuto estratto troppo corto o vuoto: '{result_str[:100] if result_str else 'EMPTY'}'")
        logger.error(f"Tipo risultato: {type(result)}")
        raise RuntimeError(
            "L'agente non ha generato un'email completa. "
            "Contenuto estratto troppo corto. Verifica il prompt e i tool."
        )
    
    logger.info(f"Contenuto estratto (tipo: {type(result_str)}, lunghezza: {len(result_str)})")
    
    # Assicurati che sia una stringa
    if not isinstance(result_str, str):
        logger.error(f"Il risultato non √® una stringa: {type(result_str)}")
        result_str = str(result_str)
    
    # Filtra righe JSON dei tool calls (formato: {"type": "tool_call", ...})
    lines = result_str.split('\n')
    filtered_lines = []
    for line in lines:
        stripped = line.strip()
        # Skip righe che sembrano JSON di tool calls
        if stripped.startswith('{"type":') and ('"tool_call"' in stripped or '"tool_result"' in stripped):
            continue
        filtered_lines.append(line)
    result_str = '\n'.join(filtered_lines)
    
    # 6. Salva draft
    draft_path = save_draft(result_str, config, logger)
    logger.info(f"‚úì Draft salvato: {draft_path}")
    logger.info("=== Agent workflow completato con successo ===")
    
    return draft_path


def extract_ga4_data_for_yesterday(config: dict, logger: logging.Logger) -> tuple:
    """
    Estrae dati GA4 per ieri e li salva nel database.
    
    Usa service layer centralizzato (stessa implementazione di main.py).
    
    Args:
        config: Configurazione caricata
        logger: Logger per messaggi
    
    Returns:
        Tuple (success: bool, date: str) - data estratta se successo
    """
    try:
        # Import service layer
        from ga4_extraction.factory import GA4ResourceFactory
        from ga4_extraction.services import GA4DataService
        
        logger.info("Inizio estrazione dati GA4 per ieri...")
        
        # Crea risorse usando factory
        db, cache = GA4ResourceFactory.create_from_config(config)
        
        # Crea service
        with GA4DataService(db, cache) as service:
            # Estrai e salva per ieri (con check esistenza automatico)
            success, target_date = service.extract_and_save_for_yesterday(force=False)
            
            if success:
                logger.info(f"‚úì Dati disponibili per {target_date}")
                return True, target_date
            else:
                logger.error("Errore estrazione/salvataggio dati")
                return False, None
        
    except Exception as e:
        logger.error(f"Errore estrazione GA4: {e}", exc_info=True)
        return False, None


def main():
    """
    Funzione principale per esecuzione standalone.
    
    Workflow:
    1. Estrae dati GA4 per ieri
    2. Salva in database + Redis
    3. Genera email con l'agente
    """
    print("=" * 60)
    print("  ü§ñ AGENT DAILY REPORT - Esecuzione On-Demand")
    print("=" * 60)
    print()
    
    try:
        # 1. Carica configurazione
        print("üìã Caricamento configurazione...")
        config = load_config()
        print("‚úì Configurazione caricata\n")
        
        # 2. Setup logging
        logger = setup_logging(config)
        
        # 3. Estrai dati GA4 per ieri
        print("üìä Estrazione dati GA4 per ieri...")
        print("   (Questo pu√≤ richiedere alcuni secondi)")
        print()
        
        success, extracted_date = extract_ga4_data_for_yesterday(config, logger)
        
        if not success:
            print("\n‚ùå ERRORE: Estrazione GA4 fallita")
            print()
            print("‚ö†Ô∏è  POSSIBILI CAUSE:")
            print("   1. Credenziali Google Analytics non valide o scadute")
            print("   2. Problema di connessione alla API di Google")
            print("   3. Configurazione GA4 non corretta")
            print()
            print("üìù VERIFICA:")
            print("   - File credentials/token.json √® presente e valido")
            print("   - La configurazione in ga4_extraction/config.py √® corretta")
            print("   - Log dettagliati in: ga4_extraction.log")
            print()
            sys.exit(1)
        
        print(f"‚úì Dati estratti e salvati per {extracted_date}\n")
        
        # 4. Esegui workflow agente
        print("üß† Creazione agente con memoria Redis...")
        print("üöÄ Esecuzione task agente...")
        print("-" * 60)
        
        # Skip data check perch√© abbiamo appena estratto i dati
        draft_path = run_agent_workflow(config, logger, skip_data_check=True)
        
        print("-" * 60)
        print()
        
        # 5. Riepilogo finale
        print("=" * 60)
        print("  ‚úÖ ESECUZIONE COMPLETATA CON SUCCESSO")
        print("=" * 60)
        print()
        print(f"üìß Draft email salvato in: {draft_path}")
        print()
        print("üìù PROSSIMI PASSI:")
        print(f"   1. Rivedi il contenuto: cat {draft_path}")
        print("   2. Se soddisfatto, approva: uv run approve_draft.py")
        print("   3. Se non soddisfatto, modifica config.yaml e riesegui")
        print()
        
    except FileNotFoundError as e:
        print(f"\n‚ùå ERRORE: {e}")
        sys.exit(1)
    
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Esecuzione interrotta dall'utente")
        sys.exit(130)
    
    except Exception as e:
        print(f"\n‚ùå ERRORE IMPREVISTO: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

